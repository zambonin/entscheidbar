\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[colorlinks]{hyperref}
\usepackage{amssymb, amsmath, algorithm, algorithmic, color, listings}

\definecolor{codegreen}{rgb}{0, 0.6, 0}
\definecolor{codegray}{rgb}{0.5, 0.5, 0.5}
\definecolor{codepurple}{rgb}{0.58, 0, 0.82}

\lstset{
  basicstyle=\tiny\ttfamily,
  breaklines=true,
  commentstyle=\color{codegreen},
  extendedchars=true,
  keywordstyle=\color{blue},
  numbers=left,
  numberstyle=\tiny\color{codegray},
  showstringspaces=false,
  stringstyle=\color{codepurple}
}

\sloppy

\renewcommand{\algorithmiccomment}[1]{\hfill $\triangleright$ #1}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\title{Solution to a Simplified Halting Problem\footnote{
    As submitted to the INE410113 class (Theory of Computation). \href{https://github.com/zambonin/ine410113}{Source code}.}}

\author{Douglas Martins\inst{1}, Emmanuel Podestá Jr.\inst{1}, Gustavo Zambonin\inst{1}}

\address{Departamento de Informática e Estatística, Universidade Federal de Santa Catarina \\
  88040-900, Florianópolis, Brazil
  \email{\{marcelino.douglas,emmanuel.podesta,gustavo.zambonin\}@posgrad.ufsc.br}
}

\begin{document} 

\maketitle

\section{Introduction}\label{sec:intro}

The halting problem is well known in computability theory. In 1937, Turing proved~\cite{Turing:article:1937:jan} a groundbreaking result related to this problem. In modern terms, the proof states that an algorithm, which use is to determine whether a Turing machine processing a given program stops, cannot exist. More precisely, this problem can be defined as a decision problem and determines if a program will continue running or not based on a generic machine-program input pair. Formally, it can be defined as follows. Consider a Turing machine, that accepts as input a machine $M$ and an aptly encoded program $w$, \emph{i.e.} $Halt_{TM} = \{(M, w) \mid M \text{ halts with } w\}$. Additionally, let $H$ be a machine that solves $Halt_{TM}$ if, for any input $(M, w)$, $H$ either accepts or rejects. 

We cannot build such a machine $H$, hence $Halt_{TM}$ is undecidable. We give a short proof in the sequence. Suppose that machine $H$ exists and decides $Halt_{TM}$, and let <$A$> be a codification of a Turing machine $A$. We introduce a new machine $B$ that takes $A$ and runs $H$ with $(A, \text{<}A\text{>})$, and halts if and only if $H$ rejects. Moreover, consider that $B$ receives as input <$B$>, and will run $H$ with $(B, \text{<}B\text{>})$. This scenario has two outcomes: (i) if $H$ accepts, then $B$ halts on input <$B$>. However, by definition, $B$ will enter in loop if $H$ accepts. Hence, $B$ on input <$B$> does not halt; and (ii) if $H$ rejects, then $B$ does not halt on input <$B$>. However, by definition, $B$ will terminate if $H$ rejects. Hence, $B$ halts on input <$B$>. Therefore, the halting problem is undecidable.

As an alternative, we can use reduction to prove that a problem is undecidable. More precisely, a problem $A$ is reducible to $B$ if $B$ can be used to solve $A$. Hence, if $A$ is undecidable, is enough to show that a solution in $B$ can be used to decide $A$, unveiling a contradiction, and thus demonstrating that $B$ is undecidable. Based on this property, if the halting problem was shown to be decidable, several problems would also be decidable. For instance, Goldbach's conjecture and calculation of the Kolmogorov complexity of a program.

We can simplify the halting problem to transform it into decidable, by means of adding restrictions to the possible machine-program pairs. In the following sections, we will define and solve an instance of a simplified halting problem. Moreover, details about the implementation and a proof of the problem decidability will be unveiled.

\section{Simplified Halting Problem}\label{sec:halting}

It is known that there exists no algorithm which can determine if any program halts or not, as seen above. However, there exist deciders that can know if strings belong to a certain formal language. This is exactly the set of recursive languages. For instance, every context-free language is decidable~\cite[Theorem 4.9]{Sipser:book:2012}. Many other examples of languages that always halt exist. Such is the case of what we call the Simplified Halting Problem (SHP), described by Demasi~\cite{Demasi:misc:2013:may} in an assembly-like format. We briefly cover its details and prove that it is decidable after.

The main characteristics of SHP lie in their limited syntax and arithmetic operations. Commands are divided into three groups: (i) usual conditional branches that compare two integers and a copy operation; (ii) arithmetic calculations modulo $1000$, with the additional restriction that dividing and taking the modulo of zero is equal to zero itself; (iii) looping constructs in the form of a \texttt{CALL} command, and program return \texttt{RET}, that accept one argument. Further, there are ten registers that compose the ``memory'', where \texttt{R0} and \texttt{R9} receive input and place the output from the third group of commands, respectively. Finally, programs have an upper bound of a hundred lines.

Note that there is only one method of looping, that is, recursive. This is exactly what the \texttt{CALL} command achieves. As such, to execute programs of this language, it is imperative to maintain a recursion stack and ``program counters''. Moreover, all ``memory'' is preserved between recursion calls, except for the last register. \texttt{R1} to \texttt{R8} can be seen as scratchpad registers. We present below an example of source code for SHP and execute it step-by-step. Note that syntactic limitations such as delimitation of conditional branches and uppercase enforcement is not discussed. The first line informs that the program has $8$ lines and that its first input is $9$.

{\footnotesize
\begin{verbatim}
8 9
IFEQ R0,0
RET 1
ENDIF
MOV R1,R0
SUB R1,1
CALL R1
MUL R9,2
RET R9
\end{verbatim}}

We will start by comparing equality of $\texttt{R0} = 9$ and $0$ and returning $1$ if so. This is the stop condition of the recursive loop. Then, we copy \texttt{R0} to \texttt{R1}, and decrement \texttt{R1}. We save the ``memory'' state and start a new execution of the program with $\texttt{R1} = 8$ as \texttt{R0}. This is repeated until the stopping condition is reached, and thus, the recursion stack has nine entries. When \texttt{RET 1} is executed, $\texttt{R9} = 1$ and the ``program counter'' moves to the \texttt{MUL} instruction, since it is directly after \texttt{CALL}. Then, \texttt{R9} is doubled and returned, once again to the line below \texttt{CALL}, since it was the origin of the recursion. 

We can see that this is repeated as long as there are entries in the stack. Since the stopping condition returns $1$ and that is doubled repeatedly, the point of this program is to recursively calculate the $n$-th power of $2$, where $n$ is the recursion depth and, indeed, the input of the program.

Now, we turn to the question on whether SHP is decidable. Evidently, the language has a finite number of configurations, due to its limited arithmetic operations and memory bank. This behaviour is independent of the instruction that modified the program state, since a given configuration can be reached from different lines. By this reasoning, it is enough to check that the number of lines executed is greater than the number of possible configurations. This is akin to say that the language is as powerful as a linear bounded automaton.

This strategy, albeit correct, will not yield the necessary performance on simple programs such as \texttt{CALL R0; RET R0}. The state for this program actually never changes, and still, to identify its non-halting behaviour, one would have to go through all the possible program configurations. However, note that if a configuration is reached more than once, this means exactly that an infinite loop exists. That is, a state that leads to itself will never exit this connection. The pigeonhole principle is the formalisation of this notion. 

Identifying state repetitions is a simpler approach, since it needs not to look at all the possible states for a program. Since it cannot have more than $100$ lines, the only instruction that can alter this behaviour semantically is \texttt{CALL}, by means of its looping capabilities. Hence, infinite loops only happen when two configurations are equal, exactly when those instructions are executed. Thus, it is only necessary to check for situations of this case.

With this information in mind, we need only to define what is such a configuration in the context of SHP. Recall that no additional information on the depth level or line number is needed. Then, we define the ``memory state'', that is, the sequence of registers \texttt{R0} to \texttt{R9}, as the configuration. By means of checking if a ``memory state'' has already occurred within former \texttt{CALL} instructions, one can identify if an infinite loop will occur. Ergo, it is always possible to know whether a program will halt or not. Thus, SHP is decidable.

\section{Implementation}\label{sec:imp}

The full source code for the SHP language parsing and execution unit can be read in Appendix~\ref{app:impl}, stripped of comments for brevity. We shortly discuss it in the sequence. Data structures were carefully chosen to prevent data access overhead. As such, unordered maps and sets are heavily featured, since their underlying STL implementation is a red-black tree. Additionally, hashing functions were created, to enable insertion of custom structures into these containers. 

We parse the input with regular expression rules created from the description of the problem~\cite{Demasi:misc:2013:may} and check for any syntax errors. We must note that, while the program description says that arithmetic is limited to modular arithmetic modulo $1000$, there exists a wrong input program that features exactly this number. Hence, the program has a workaround to accept this variable. Further, the input value limit of $100$ is also not respected --- we believe it is a typo and should be $0 \leq n < 1000$. Helper functions that translate values from the ``memory'' and parse each program line into a valid ``instruction'' are given shortly below.

Lines 115--159 present the function that loops over an entire program and evaluates its lines, following the control flow if needed. It takes into account a ``program counter'' and a recursion stack, essential to simulate the inner works of the toy language. If instructions are arithmetic or conditional, a function map is invoked to decide what should be executed. Further, in the case of arithmetic functions, recall that operations have to follow a set of rules that, for instance, allow division by zero.

The most complex behaviour of the code, however, is met when parsing instructions that enter and exit recursion states. An optimisation is added here, that features memoisation of previously calculated recursion states. This allows the code to pass the $\frac{1}{8}$ of a second time target, since there are input programs that calculate large Fibonacci numbers, and it is known that if intermediary results are not memoised, this calculation will take a very long time. Evidently, the recursion stack is modified, the ``program counter'' is reset, and values are returned as usual.

Within this code, the strategy for preventing infinite loops is also implemented. It is enough to compare if a recursion state has already occurred, as discussed above. Note that the hashing function used in this comparison was not carefully constructed as to prevent collisions, but it seems to distribute all ``memory'' states distinctly. Finally, once the instruction is parsed, the ``program counter'' is incremented and the program may return if it finished its execution.

All programs are executed and results are printed according to the problem definition. After determining its correct parsing and execution of the toy language, the code takes $30$ ms to calculate the entirety of the input. Parsing instructions uses a considerable amount of time, but this cannot be memoised, \emph{e.g.} \texttt{ADD R1,R2} may appear in two programs, but have completely different meanings depending on the contents of the ``memory'' at each ``program counter'' state.

Using simpler string structures, manual translation of strings to integers, and substituting the ``memory'' from a map to an array lead the code to execute in $4$ ms. Correctly emulating recursion loops, as well as these performance improvements, were the main obstacles. Further optimisations can be achieved if large parts of the code is rewritten, for instance, removing function maps and regular expressions. Ergo, to prevent reduction of code readability and maintenance, we leave it as is.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\appendix

\section{C++ implementation of SHP}\label{app:impl}
\lstinputlisting[language=C++]{halting.cpp}

\end{document}